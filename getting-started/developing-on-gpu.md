# Developing on GPU

While one can run a Jupyter Notebooks session with one command in a command line or with one click in web UI, we recommend project-based development. To simplify the process, we provide the project template, which is a part of **Neu.ro Toolbox**, and provides the folder structure and integrations with several recommended tools.

### Initializing a project

To initialize a new project from the template, run:

```text
neuro project init
```

This command asks several questions about your project:

```text
project_name [Name of the project]: Neuro Tutorial
project_slug [neuro-tutorial]:
code_directory [modules]:
```

You can press Enter if you agree with the suggested choice.

To navigate to the project directory, run:

```text
cd neuro-tutorial
```

### Project structure

After you execute the command mentioned above, you get the following structure:

```text
neuro-tutorial
├── config/             <- configuration files for various integrations
├── data/               <- training and testing datasets (we do not keep it under source control)
├── notebooks/          <- Jupyter notebooks
├── modules/            <- source code of models
├── results/            <- training artifacts
├── .gitignore          <- default .gitignore for a Python ML project
├── HELP.md             <- autogenerated template reference
├── Makefile            <- various ML development tasks (see `make help`)
├── README.md           <- autogenerated informational file
├── apt.txt             <- list of system packages to be installed in the training environment
├── requirements.txt    <- list of Python dependencies to be installed in the training environment
└── setup.cfg           <- linter settings (Python code quality checking)
```

The template contains Makefile, which guarantees the contract between the above-shown structure, the base environment which we provide, and manipulations with storage and jobs. For example, through `upload-*` and `download-*` commands, sub-folders on your local machine are synced with sub-folders on persistent platform storage, and those sub-folders are synced with the corresponding sub-folders in job containers.

### Setting up the environment and running Jupyter

To set up the project environment, run:

```text
make setup
```

Upon execution of this command, system packages from `apt.txt` and pip dependencies from `requirements.txt` are installed in the base environment, which already contains CUDA support and the most popular ML/AI frameworks, like Tensorflow and Pytorch.

To start a Jupyter Notebooks session on GPU, run:

```text
make jupyter
```

This command open Jupyter Notebooks interface in your default browser.

Now, when you edit notebooks, they update on your platform storage. To download them locally \(for example, to put them under version control\), run:

```text
make download-notebooks
```

Don’t forget to terminate your job when you no longer need it \(the files won’t disappear after that\):

```text
make kill-jupyter
```

To check how much GPU and CPU hours you have left, run:

```text
neuro config show-quota
```

