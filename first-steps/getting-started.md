# Начало работы

## Введение

Перед тем, как начинать работу с платформой, вам потребуется сделать следующее:

1. [Установить клиент CLI](getting-started.md#ustanovka-cli).
2. [Разобраться с основными понятиями платформы](getting-started.md#razrabotka-na-gpu-s-pomoshyu-jupyter-notebooks).

После этого вы можете свободно исследовать платформу и её функциональность. Хорошим вступлением может послужить секция о [разработке на GPU с помощью Jupyter Notebooks](getting-started.md#developing-on-gpu-with-jupyter-notebooks).

## Установка CLI

[Веб-терминал](http://apps.ml.cloud.mts.ru) не требует установки и может быстро познакомить вас с платформой, позволяя работать в браузере.

С другой стороны, локальная установка CLI может оказаться более удобным способом долгосрочного взаимодействия с платформой:

* Вам не нужно будет платить просто за запуск заданий, как в Web UI.
* Ваш исходный код и другие локальные файлы будут сохраняться прямо на ваш рабочий компьютер.

### Инструкции по установке

{% tabs %}
{% tab title="Linux и Mac OS" %}
#### Установка с помощью pipx

Наш пакет _neuro-all_, доступный в pipx автоматически установит все необходимые компоненты:&#x20;

```
$ pip install pipx
$ pipx install neuro-all
$ pipx upgrade neuro-all
```

#### Установка с помощью pip

Вы также можете установить все компоненты с помощью соответствующих пакетов pip.

Neu.ro CLI требует установленный Python 3 (рекомендуется: 3.8; требуется: 3.6.6 или более, 3.7.9 или более). Мы советуем использовать [дистрибутив Anaconda Python 3.8](https://www.anaconda.com/distribution/).

```
$ pip install -U neuro-cli neuro-extras neuro-flow
$ neuro login
```

Если ваш рабочий компьютер не обладает GUI, используйте следующую команду вместо `neuro login`:

```
$ neuro config login-headless
```
{% endtab %}

{% tab title="Windows" %}
#### Установка с помощью pipx

Наш пакет _neuro-all_, доступный в pipx автоматически установит все необходимые компоненты:&#x20;

```
$ pip install pipx
$ pipx install neuro-all
$ pipx upgrade neuro-all
```

#### Установка с помощью pip

Вы также можете установить все компоненты с помощью соответствующих пакетов pip.

Мы настоятельно рекомендуем использовать [дистрибутив Anaconda Python 3.8](https://www.anaconda.com/distribution/) с настройками по умолчанию.

После установки Anaconda дистрибутива Python 3.7 выполните следующие команды в Conda Prompt:

```
$ conda install -c conda-forge make
$ conda install -c conda-forge git    
$ pip install -U neuro-cli neuro-extras neuro-flow
$ pip install -U certifi
$ neuro login
```

Чтобы удостовериться, что все команды, встречающиеся в нашей документации, работают корректно, не забывайте запускать `bash` \_\*\*\_при каждом открытии Conda Prompt.
{% endtab %}
{% endtabs %}

## Основные понятия

На уровне **Neu.ro Core**, происходит работа с заданиями, рабочим окружением и системой хранения (дисковым пространством). Проще говоря, возможно запустить задание (исполнительный блок) в заданном рабочем окружении (Docker контейнер), с заданными характеристиками (комбинация ресурсов CPU, GPU и памяти) и с несколькими подключенными блоками для хранения данных (блоки или объекты хранения).

Продемонстрируем это на нескольких примерах.

### Hello, World!

Запустим на CPU задание, которое выводит “Hello, World!” и останавливается:

```
neuro run --preset cpu-small --name test ubuntu echo Hello, World!
```

После запуска данной команды в терминале Вы увидите следующее:

```
√ Job ID: job-7dd12c3c-ae8d-4492-bdb9-99509fda4f8c
√ Name: test
- Status: pending Creating
- Status: pending Scheduling
√ Http URL: https://test--jane-doe.jobs.default.org.neu.ro
√ The job will die in a day. See --life-span option documentation for details.
√ Status: succeeded
√ =========== Job is running in terminal mode ===========
√ (If you don't see a command prompt, try pressing enter)
√ (Use Ctrl-P Ctrl-Q key sequence to detach from the job)
Hello, World!
```

### Простое задание на GPU

Запустим задание на GPU в рабочем окружении по умолчанию (`neuromation/base`), которое показывает, доступно ли CUDA в данном рабочем окружении:

```
neuro run --preset gpu-k80-small --name test neuromation/base python -c "import torch; print(torch.cuda.is_available());"
```

Здесь мы использовали пресет `gpu-k80-small` для запуска задания. Чтобы увидеть полный список доступных пресетов, запустите команду:

```
$ neuro config show
```

### Работа с дисковым пространством платформы

Создадим каталог `demo` в корне доступного вам дискового пространства платформы:

```
$ neuro mkdir -p storage:demo
```

Запустим команду, которая монтирует каталог `demo` на дисковом пространстве к папке `/demo` в контейнере задания и создает в нём файл:

```
$ neuro run --preset cpu-small --name test --volume storage:demo:/demo:rw ubuntu bash -c "echo Hello >> /demo/hello.txt"
```

Убедитесь, что файл, который вы только что создали, действительно находится на дисковом пространстве:

```
$ neuro ls storage:demo
```

## Разработка на GPU с помощью Jupyter Notebooks

Разработка с помощью Jupyter Notebooks является хорошим примером использования платформы. Хотя сеанс Jupyter Notebooks можно запустить с помощью одной команды в командной строке или одним щелчком мыши в веб-интерфейсе, мы рекомендуем вести разработку на основе проектов. Чтобы упростить процесс, мы предоставляем шаблон проекта, который является частью **Toolbox.** Этот шаблон предоставляет базовую структуру папок и интеграцию с несколькими рекомендуемыми инструментами.

### Создание проекта

Чтобы создать новый проект из шаблона, выполните команду:

```
$ neuro project init
```

Данная команда задает несколько вопросов относительно Вашего проекта:

```
project_name [Name of the project]: Neuro Tutorial
project_slug [neuro-tutorial]:
code_directory [modules]:
```

{% hint style="info" %}
Значения по умолчанию занесены в квадратные скобки **\[ ].** Вы можете использовать их, нажимая **Enter**.
{% endhint %}

Чтобы перейти к каталогу проекта, введите команду:

```
$ cd neuro-tutorial
```

### Структура проекта

Структура папки с проектом будет выглядеть следующем образом:

```
neuro-tutorial
├── .neuro/             <- конфигурационные файлы neuro и neuro-flow CLI
├── config/             <- конфигурационные файлы различных интеграций
├── data/               <- наборы данных для тестов и тренировки (они не привфязаны к системе контроля версий)
├── notebooks/          <- Jupyter notebooks
├── modules/            <- исходный код моделей
├── results/            <- артефакты обучения
├── .gitignore          <- .gitignore-файл для проекта Python ML
├── .neuro.toml         <- автоматически сгенерированный конфигурационный файл
├── HELP.md             <- автоматически сгенерированная справка шаблона
├── README.md           <- автоматически сгенерированный информационный файл
├── Dockerfile          <- описание базового образа вашего проекта
├── apt.txt             <- список системных пакетов, устанавливающихся в тренировочной среде
├── requirements.txt    <- список зависимостей Python, устанавливающихся в тренировочной среде
└── setup.cfg           <- настройки linter'а (проверка качества Python-кода)
```

Шаблон содержит файл конфигурации `.neuro/live.yaml` для `neuro-flow`. Этот файл обеспечивает связь между указанной выше структурой файлов и каталогов, базовым рабочим окружением, которое мы предоставляем и манипуляциями с дисковым пространством и заданиями. Например, с помощью команды `upload` подпапки на Вашем локальном компьютере синхронизируются с подпапками на дисковом пространстве платформы, а подпапки на дисковом пространстве синхронизируются с соответствующими подпапками в контейнерах заданий.

### Настройка рабочей среды и запуск Jupyter

Чтобы настроить рабочее окружение, выполните:

```
$ neuro-flow build myimage
$ neuro-flow mkvolumes
```

После выполнения данных команд в базовую среду будут установлены системные пакеты из `apt.txt` и pip-зависимости из файла `requirements.txt`. Эта среда уже содержит поддержку CUDA и наиболее популярные пакеты ML/AL, такие как Tensorflow и Pytorch.

Для того, чтобы Jupyter Notebooks корректно работали, скрипт `train.py` должен быть доступен на дисковом пространстве платформы. Загрузите папку `code`, содержащую этот файл, на дисковое пространство платформы с помощью такой команды:

```
$ neuro-flow upload code
```

Теперь вам нужно выбрать пресет, на котором будут запускаться ваши задания Jupyter. Чтобы просмотреть список пресетов, доступных на текущем кластере, запустите:

```
$ neuro config show 
```

Для запуска сессии Jupyter Notebooks на GPU, выполните:

```
$ neuro-flow run jupyter --preset <имя-пресета>
```

Эта команда откроет интерфейс Jupyter Notebooks в вашем браузере по умолчанию.

{% hint style="info" %}
Вы также можете дополнить описание задания _jupyter_, указав аргумент _**preset**_, который отразит ваш предпочитаемый пресет:

```
jupyter:
    action: gh:neuro-actions/jupyter@<version>
    args:
      ...
      preset: <имя-пресета-gpu>
      ...
```

После этого при каждом запуске задания Jupyter указанный пресет будет использоваться по умолчанию, без надобности для вас указывать его в CLI-команде:

```
$ neuro-flow run jupyter 
```

[Больше информации об аргументах описания заданий можно найти здесь](https://github.com/neuro-actions/jupyter#arguments)
{% endhint %}

Теперь, когда Вы пишете программу в Jupyter Notebooks, она сохраняется на дисковом пространстве платформы. Чтобы сохранить ваши блокноты Jupyter локально (например, для связи с системой контроля версий), введите команду:

```
$ neuro-flow download notebooks
```

Не забудьте закончить работу задания, когда оно Вам больше не нужно (файлы после этого не пропадут):

```
$ neuro-flow kill jupyter
```

Чтобы проверить, сколько кредитов у вас осталось, запустите команду:

```
$ neuro config show-quota
```
