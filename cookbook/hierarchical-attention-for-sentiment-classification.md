# Hierarchical Attention для классификации тональности текста

[Запуск на Neu.ro](https://apps.neu.ro/ml-recipes/hier-attention)

[Репозиторий на GitHub](https://github.com/neuromation/ml-recipe-hier-attention)

Рецепт основан на известной статье, [Hierarchical Attention Networks for Document Classification](https://arxiv.org/abs/1608.07775) \(Z. Yang et al.\), опубликованной в 2017 году. Мы будем классифицировать отзывы IMDB как положительные и отрицательные \(25 тысяч отзывов для обучения и столько же для тестирования\). Предлагаемая архитектура нейронной сети делает два шага:

1. Кодировка **предложений**. Механизм классификации предсказывает важность каждого **слова** при окончательном встраивании в **предложение**.
2. Кодировка **текста**. Механизм классификации предсказывает важность каждого **предложения** при окончательном встраивании в **текст**.

Данная архитектура интересна тем, что позволяет нам для лучшего понимания, создать иллюстрацию, какие слова и предложения были важны для прогноза. Более подробную информацию можно найти в оригинальной статье.

Архитектура Hierarchical Attention Network \(HAN\):

![](../.gitbook/assets/scheme.png)

Этот рецепт включает в себя два сценария:

* Вы можете **обучить модель** самостоятельно с нуля, с возможностью вносить изменения в обработку данных или архитектуру, это не сложно. 
* Вы можете **исследовать обученную модель** в Jupyter notebook. Сделайте свой обзор или выберите случайный из набора тестов, а затем визуализируйте прогнозы.

![](../.gitbook/assets/visualization.png)

### Технологии

* `Catalyst` как конвейер для задач глубокого обучения. Эта новая и быстро развивающаяся [библиотека](https://github.com/catalyst-team/catalyst) может значительно сократить объем стандартного кода. Если вы знакомы с экосистемой TensorFlow, вы можете думать о Catalyst как о Keras для PyTorch. Этот фреймворк интегрирован с системами логирования, такими как хорошо известный [TensorBoard](https://www.tensorflow.org/tensorboard) и новый [Weights & biases](https://www.wandb.com/).
* `Pytorch` и `Torchtext` как основные фреймворки для глубокого обучения. 
* `NLTK` для предварительной обработки данных.

## Начало работы

#### 0. Зарегистрироваться

#### 1. Установить CLI и зайти

```text
pip install -U neuro-cli neuro-extras neuro-flow
neuro login
```

#### 2. Запустить рецепт

```text
git clone git@github.com:neuromation/ml-recipe-hier-attention.git
cd ml-recipe-hier-attention
make setup
make jupyter
```

